{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict, deque\n",
    "import time, glob, os, natsort, sys, cv2, os, json, math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.utils.linear_assignment_ import linear_assignment\n",
    "from numpy import dot\n",
    "from scipy.linalg import inv, block_diag\n",
    "\n",
    "\n",
    "labelsPath = os.path.join(os.getcwd(), \"yolo_files/classes.names\")\n",
    "weightsPath = os.path.join(os.getcwd(), \"yolo_files/yolov3.weights\")\n",
    "configPath = os.path.join(os.getcwd(), \"yolo_files/yolov3.cfg\")\n",
    "confidence_t = 0.5\n",
    "threshold_t = 0.3\n",
    "img_size = 416\n",
    "\n",
    "annot_path = os.path.join(os.getcwd(), \"MVI_40852.xml\")\n",
    "img_folder = os.path.join(os.getcwd(), \"MVI_40852/*\")\n",
    "file_paths = glob.glob(img_folder)\n",
    "sorted_file_paths = natsort.natsorted(file_paths, reverse=False)\n",
    "\n",
    "\n",
    "maxDisappeared = 10  # no.of consecutive unmatched detection before a track is deleted\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_size = 0.8\n",
    "font_color = (255, 0, 0)\n",
    "output_FPS = 10  # Frames per second of output video\n",
    "max_objects = 50 # Maximum number of vehicles that can be in a frame at some time. Should not exceed this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDistance(x1,y1,x2,y2):\n",
    "    dist = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    return dist\n",
    "\n",
    "\n",
    "\n",
    "def convert_frames_to_video(frames, output_video_path):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Be sure to use lower case\n",
    "    height, width, channels = frames[0].shape\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, output_FPS, (width, height))\n",
    "    for i, ff in enumerate (frames):\n",
    "        out.write(ff)\n",
    "    out.release\n",
    "    cv2.destroyAllWindows()\n",
    "    return\n",
    "\n",
    "\n",
    "def yolov3_process(image):\n",
    "    LABELS = open(labelsPath).read().strip().split('\\n')\n",
    "    names = []\n",
    "    np.random.seed(42)\n",
    "    COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")\n",
    "\n",
    "    # image should be a 3d numpy array\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    # Let's apply Yolo dectector using pretrained weights\n",
    "    net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (img_size, img_size),swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    start = time.time()\n",
    "    layerOutputs = net.forward(ln)\n",
    "    end = time.time()\n",
    "#     print(\"[INFO] YOLO took {:.6f} seconds\".format(end - start))\n",
    "\n",
    "    # Let us assign class labels to the objects from layerOutputs\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "\n",
    "    locations_car = []\n",
    "    confi_car = []\n",
    "\n",
    "    locations_bus = []\n",
    "    confi_bus = []\n",
    "    \n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if confidence > confidence_t:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping bounding\n",
    "\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, confidence_t,threshold_t)\n",
    "\n",
    "    # Let's make output image and store class labels in a list\n",
    "    # ensure at least one detection exists\n",
    "    if len(idxs) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in idxs.flatten():\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            l = np.array([x,y,x+w, y+h])\n",
    "#             print((LABELS[classIDs[i]]))\n",
    "\n",
    "            # draw a bounding box rectangle and label on the image\n",
    "            if (LABELS[classIDs[i]] == \"car\"):\n",
    "                confi_car.append(confidences[i])\n",
    "                locations_car.append(l)\n",
    "                cv2.rectangle(image, (x, y), (x+w, y+h),(0, 255, 0), 2)\n",
    "                cv2.rectangle(image, (x-1, y-15), (x+w+1, y), (0,255,0), -1, 1)\n",
    "                # Output the labels that show the x and y coordinates of the bounding box center.\n",
    "                text = LABELS[classIDs[i]]\n",
    "                cv2.putText(image,text,(x,y-3), font, font_size, font_color, 1, cv2.LINE_AA)\n",
    "                \n",
    "            elif (LABELS[classIDs[i]] == \"bus\"):\n",
    "                confi_bus.append(confidences[i])\n",
    "                locations_bus.append(l)\n",
    "                cv2.rectangle(image, (x, y), (x+w, y+h),(0, 255, 0), 2)\n",
    "                cv2.rectangle(image, (x-1, y-15), (x+w+1, y), (0,255,0), -1, 1)\n",
    "                # Output the labels that show the x and y coordinates of the bounding box center.\n",
    "                text = LABELS[classIDs[i]]\n",
    "                cv2.putText(img,text,(x,y-3), font, font_size, font_color, 1, cv2.LINE_AA)\n",
    "\n",
    "                \n",
    "#     cv2.imshow(\"Image\", img)\n",
    "#     cv2.waitKey(0)\n",
    "\n",
    "#     dictionary_car = {'confidences': confi_car, 'locations': locations_car}\n",
    "#     dictionary_bus = {'confidences': confi_bus, 'locations': locations_bus}\n",
    "\n",
    "    return locations_car, locations_bus, image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cars detected: 1490\n",
      "Number of buses detected: 0\n"
     ]
    }
   ],
   "source": [
    "total_pred_car = 0\n",
    "pred_car = []\n",
    "total_pred_bus = 0\n",
    "pred_bus = []\n",
    "\n",
    "img_id = []\n",
    "tree = ET.parse(annot_path)\n",
    "root = tree.getroot()\n",
    "ignored_boxes = tree.findall('ignored_region')\n",
    "images = []\n",
    "\n",
    "for i, f in enumerate(sorted_file_paths):\n",
    "    img_id.append(i+1)\n",
    "    img = cv2.imread(f, 1)\n",
    "    \n",
    "    for child in ignored_boxes[0]:\n",
    "        aa = child.attrib\n",
    "        x1 = int(float(aa.get('left')))\n",
    "        y1 = int(float(aa.get('top')))\n",
    "        w = int(float(aa.get('width')))\n",
    "        h = int(float(aa.get('height')))\n",
    "        x2 = x1+w\n",
    "        y2 = y1+h\n",
    "\n",
    "        for j in range (h):\n",
    "            for k in range (w):\n",
    "                img[y1+j, x1+k] = [255, 255, 255]\n",
    "\n",
    "    img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    list_car, list_bus, image = yolov3_process(img)\n",
    "    images.append(image)\n",
    "#         dict_car, dict_bus = maskrcnn_process(img)\n",
    "    total_pred_car = total_pred_car + len(list_car)\n",
    "    pred_car.append(list_car)\n",
    "    \n",
    "    total_pred_bus = total_pred_bus + len(list_bus)\n",
    "    pred_bus.append(list_bus)\n",
    "\n",
    "\n",
    "print(\"Number of cars detected: \"+str(total_pred_car))\n",
    "print(\"Number of buses detected: \"+str(total_pred_bus))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "dict_pred_car = {'image_id': img_id, 'frame_predictions': pred_car, 'frames': images}\n",
    "dict_pred_bus = {'image_id': img_id, 'frame_predictions': pred_bus, 'frames': images}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centroid Tracker ( Gives noisy trajectory )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidTracker():\n",
    "\tdef __init__(self, maxDisappeared=maxDisappeared):\n",
    "\t\t# initialize the next unique object ID along with two ordered\n",
    "\t\t# dictionaries used to keep track of mapping a given object\n",
    "\t\t# ID to its centroid and number of consecutive frames it has\n",
    "\t\t# been marked as \"disappeared\", respectively\n",
    "\t\tself.nextObjectID = 0\n",
    "\t\tself.objects = OrderedDict()\n",
    "\t\tself.disappeared = OrderedDict()\n",
    "\n",
    "\t\t# store the number of maximum consecutive frames a given\n",
    "\t\t# object is allowed to be marked as \"disappeared\" until we\n",
    "\t\t# need to deregister the object from tracking\n",
    "\t\tself.maxDisappeared = maxDisappeared\n",
    "\n",
    "\tdef register(self, centroid):\n",
    "\t\t# when registering an object we use the next available object\n",
    "\t\t# ID to store the centroid\n",
    "\t\tself.objects[self.nextObjectID] = centroid\n",
    "\t\tself.disappeared[self.nextObjectID] = 0\n",
    "\t\tself.nextObjectID += 1\n",
    "\n",
    "\tdef deregister(self, objectID):\n",
    "\t\t# to deregister an object ID we delete the object ID from\n",
    "\t\t# both of our respective dictionaries\n",
    "\t\tdel self.objects[objectID]\n",
    "\t\tdel self.disappeared[objectID]\n",
    "\n",
    "\tdef update(self, rects):\n",
    "\t\t# check to see if the list of input bounding box rectangles\n",
    "\t\t# is empty\n",
    "\t\tif len(rects) == 0:\n",
    "\t\t\t# loop over any existing tracked objects and mark them\n",
    "\t\t\t# as disappeared\n",
    "\t\t\tfor objectID in list(self.disappeared.keys()):\n",
    "\t\t\t\tself.disappeared[objectID] += 1\n",
    "\n",
    "\t\t\t\t# if we have reached a maximum number of consecutive\n",
    "\t\t\t\t# frames where a given object has been marked as\n",
    "\t\t\t\t# missing, deregister it\n",
    "\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
    "\t\t\t\t\tself.deregister(objectID)\n",
    "\n",
    "\t\t\t# return early as there are no centroids or tracking info\n",
    "\t\t\t# to update\n",
    "\t\t\treturn self.objects\n",
    "\n",
    "\t\t# initialize an array of input centroids for the current frame\n",
    "\t\tinputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "\n",
    "\t\t# loop over the bounding box rectangles\n",
    "\t\tfor (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "\t\t\t# use the bounding box coordinates to derive the centroid\n",
    "\t\t\tcX = int((startX + endX) / 2.0)\n",
    "\t\t\tcY = int((startY + endY) / 2.0)\n",
    "\t\t\tinputCentroids[i] = (cX, cY)\n",
    "\n",
    "\t\t# for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "\t\t# \t# use the bounding box coordinates to derive the centroid\n",
    "\t\t# \tcX = int((startX + endX) / 2.0)\n",
    "\t\t# \tcY = endY\n",
    "\t\t# \tinputCentroids[i] = (cX, cY)\n",
    "\n",
    "\n",
    "\t\t# if we are currently not tracking any objects take the input\n",
    "\t\t# centroids and register each of them\n",
    "\t\tif len(self.objects) == 0:\n",
    "\t\t\tfor i in range(0, len(inputCentroids)):\n",
    "\t\t\t\tself.register(inputCentroids[i])\n",
    "\n",
    "\t\t# otherwise, are are currently tracking objects so we need to\n",
    "\t\t# try to match the input centroids to existing object\n",
    "\t\t# centroids\n",
    "\t\telse:\n",
    "\t\t\t# grab the set of object IDs and corresponding centroids\n",
    "\t\t\tobjectIDs = list(self.objects.keys())\n",
    "\t\t\tobjectCentroids = list(self.objects.values())\n",
    "\n",
    "\t\t\t# compute the distance between each pair of object\n",
    "\t\t\t# centroids and input centroids, respectively -- our\n",
    "\t\t\t# goal will be to match an input centroid to an existing\n",
    "\t\t\t# object centroid\n",
    "\t\t\tD = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "\t\t\t# in order to perform this matching we must (1) find the\n",
    "\t\t\t# smallest value in each row and then (2) sort the row\n",
    "\t\t\t# indexes based on their minimum values so that the row\n",
    "\t\t\t# with the smallest value as at the *front* of the index\n",
    "\t\t\t# list\n",
    "\t\t\trows = D.min(axis=1).argsort()\n",
    "\n",
    "\t\t\t# next, we perform a similar process on the columns by\n",
    "\t\t\t# finding the smallest value in each column and then\n",
    "\t\t\t# sorting using the previously computed row index list\n",
    "\t\t\tcols = D.argmin(axis=1)[rows]\n",
    "\n",
    "\t\t\t# in order to determine if we need to update, register,\n",
    "\t\t\t# or deregister an object we need to keep track of which\n",
    "\t\t\t# of the rows and column indexes we have already examined\n",
    "\t\t\tusedRows = set()\n",
    "\t\t\tusedCols = set()\n",
    "\n",
    "\t\t\t# loop over the combination of the (row, column) index\n",
    "\t\t\t# tuples\n",
    "\t\t\tfor (row, col) in zip(rows, cols):\n",
    "\t\t\t\t# if we have already examined either the row or\n",
    "\t\t\t\t# column value before, ignore it\n",
    "\t\t\t\t# val\n",
    "\t\t\t\tif row in usedRows or col in usedCols:\n",
    "\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t# otherwise, grab the object ID for the current row,\n",
    "\t\t\t\t# set its new centroid, and reset the disappeared\n",
    "\t\t\t\t# counter\n",
    "\t\t\t\tobjectID = objectIDs[row]\n",
    "\t\t\t\tself.objects[objectID] = inputCentroids[col]\n",
    "\t\t\t\tself.disappeared[objectID] = 0\n",
    "\n",
    "\t\t\t\t# indicate that we have examined each of the row and\n",
    "\t\t\t\t# column indexes, respectively\n",
    "\t\t\t\tusedRows.add(row)\n",
    "\t\t\t\tusedCols.add(col)\n",
    "\n",
    "\t\t\t# compute both the row and column index we have NOT yet\n",
    "\t\t\t# examined\n",
    "\t\t\tunusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "\t\t\tunusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "\t\t\t# in the event that the number of object centroids is\n",
    "\t\t\t# equal or greater than the number of input centroids\n",
    "\t\t\t# we need to check and see if some of these objects have\n",
    "\t\t\t# potentially disappeared\n",
    "\t\t\tif D.shape[0] >= D.shape[1]:\n",
    "\t\t\t\t# loop over the unused row indexes\n",
    "\t\t\t\tfor row in unusedRows:\n",
    "\t\t\t\t\t# grab the object ID for the corresponding row\n",
    "\t\t\t\t\t# index and increment the disappeared counter\n",
    "\t\t\t\t\tobjectID = objectIDs[row]\n",
    "\t\t\t\t\tself.disappeared[objectID] += 1\n",
    "\n",
    "\t\t\t\t\t# check to see if the number of consecutive\n",
    "\t\t\t\t\t# frames the object has been marked \"disappeared\"\n",
    "\t\t\t\t\t# for warrants deregistering the object\n",
    "\t\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
    "\t\t\t\t\t\tself.deregister(objectID)\n",
    "\n",
    "\t\t\t# otherwise, if the number of input centroids is greater\n",
    "\t\t\t# than the number of existing object centroids we need to\n",
    "\t\t\t# register each new input centroid as a trackable object\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor col in unusedCols:\n",
    "\t\t\t\t\tself.register(inputCentroids[col])\n",
    "\n",
    "\t\t# return the set of trackable objects\n",
    "\t\treturn self.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CentroidTracker()\n",
    "\n",
    "labelled_frames = []\n",
    "num = len(pred_car)\n",
    "total_ids = np.linspace(0,max_objects-1, max_objects)\n",
    "ids = []\n",
    "XX = np.zeros(shape = (len(images), max_objects), dtype=int)\n",
    "YY = np.zeros(shape = (len(images), max_objects), dtype = int)\n",
    "\n",
    "if len(pred_car) == len(pred_bus):\n",
    "    counts = []\n",
    "\n",
    "    for i in range(len(pred_car)):\n",
    "        comp_list = pred_car[i] + pred_bus[i]\n",
    "        frame = images[i].copy()\n",
    "        objects = ct.update(comp_list)\n",
    "        c = 0\n",
    "        for (objectID, centroid) in objects.items():\n",
    "            ids.append(objectID)\n",
    "            c = c+1\n",
    "            XX[i,objectID] = centroid[0]\n",
    "            YY[i,objectID] = centroid[1]\n",
    "            \n",
    "\n",
    "length_path = len(images)\n",
    "labelled = []\n",
    "frames = images.copy()\n",
    "pts_list = []\n",
    "colors = []\n",
    "for i in range(XX.shape[1]):\n",
    "    pts_list.append(deque(maxlen=length_path))\n",
    "    colors.append((np.random.randint(low=0, high=255), np.random.randint(low=0, high=255), np.random.randint(low=0, high=255)))\n",
    "for i in range (len(images)):\n",
    "    img = frames[i].copy()\n",
    "    for j in range(XX.shape[1]):\n",
    "        pts_list[j].appendleft((XX[i,j], YY[i,j]))       \n",
    "        for i in range(1, len(pts_list[j])):\n",
    "            if pts_list[j][i - 1] is None or pts_list[j][i] is None:\n",
    "                continue\n",
    "            thickness = 4\n",
    "#             thickness = int(np.sqrt(length_path / float(i + 1)) * 2)\n",
    "            d = calculateDistance(pts_list[j][i - 1][0], pts_list[j][i-1][1], pts_list[j][i][0], pts_list[j][i][1], )\n",
    "            if d<100:\n",
    "                cv2.line(img, pts_list[j][i - 1], pts_list[j][i], colors[j], thickness)\n",
    "\n",
    "#     cv2.imshow(\"img\", img)\n",
    "#     cv2.waitKey(0)\n",
    "    labelled.append(img)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video_path = os.path.join(os.getcwd(), \"centroid_tracker.mp4\")\n",
    "convert_frames_to_video(labelled, output_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter based tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker(): # class for Kalman Filter-based tracker\n",
    "    def __init__(self):\n",
    "        # Initialize parametes for tracker (history)\n",
    "        self.id = 0  # tracker's id \n",
    "        self.box = [] # list to store the coordinates for a bounding box \n",
    "        self.hits = 0 # number of detection matches\n",
    "        self.no_losses = 0 # number of unmatched tracks (track loss)\n",
    "        \n",
    "        # Initialize parameters for Kalman Filtering\n",
    "        # The state is the (x, y) coordinates of the detection box\n",
    "        # state: [up, up_dot, left, left_dot, down, down_dot, right, right_dot]\n",
    "        # or[up, up_dot, left, left_dot, height, height_dot, width, width_dot]\n",
    "        self.x_state=[] \n",
    "        self.dt = 0.2   # time interval\n",
    "        \n",
    "        # Process matrix, assuming constant velocity model\n",
    "        self.F = np.array([[1, self.dt, 0,  0,  0,  0,  0, 0],\n",
    "                           [0, 1,  0,  0,  0,  0,  0, 0],\n",
    "                           [0, 0,  1,  self.dt, 0,  0,  0, 0],\n",
    "                           [0, 0,  0,  1,  0,  0,  0, 0],\n",
    "                           [0, 0,  0,  0,  1,  self.dt, 0, 0],\n",
    "                           [0, 0,  0,  0,  0,  1,  0, 0],\n",
    "                           [0, 0,  0,  0,  0,  0,  1, self.dt],\n",
    "                           [0, 0,  0,  0,  0,  0,  0,  1]])\n",
    "        \n",
    "        # Measurement matrix, assuming we can only measure the coordinates\n",
    "        \n",
    "        self.H = np.array([[1, 0, 0, 0, 0, 0, 0, 0],\n",
    "                           [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "                           [0, 0, 0, 0, 1, 0, 0, 0], \n",
    "                           [0, 0, 0, 0, 0, 0, 1, 0]])\n",
    "        \n",
    "        \n",
    "        # Initialize the state covariance\n",
    "        self.L = 10.0\n",
    "        self.P = np.diag(self.L*np.ones(8))\n",
    "        \n",
    "        \n",
    "        # Initialize the process covariance\n",
    "        self.Q_comp_mat = np.array([[self.dt**4/4., self.dt**3/2.],\n",
    "                                    [self.dt**3/2., self.dt**2]])\n",
    "        self.Q = block_diag(self.Q_comp_mat, self.Q_comp_mat, \n",
    "                            self.Q_comp_mat, self.Q_comp_mat)\n",
    "        \n",
    "        # Initialize the measurement covariance\n",
    "        self.R_scaler = 1\n",
    "        self.R_diag_array = self.R_scaler * np.array([self.L, self.L, self.L, self.L])\n",
    "        self.R = np.diag(self.R_diag_array)\n",
    "        \n",
    "        \n",
    "    def update_R(self):   \n",
    "        R_diag_array = self.R_scaler * np.array([self.L, self.L, self.L, self.L])\n",
    "        self.R = np.diag(R_diag_array)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def kalman_filter(self, z): \n",
    "        '''\n",
    "        Implement the Kalman Filter, including the predict and the update stages,\n",
    "        with the measurement z\n",
    "        '''\n",
    "        x = self.x_state\n",
    "        # Predict\n",
    "        x = dot(self.F, x)\n",
    "        self.P = dot(self.F, self.P).dot(self.F.T) + self.Q\n",
    "\n",
    "        #Update\n",
    "        S = dot(self.H, self.P).dot(self.H.T) + self.R\n",
    "        K = dot(self.P, self.H.T).dot(inv(S)) # Kalman gain\n",
    "        y = z - dot(self.H, x) # residual\n",
    "        x += dot(K, y)\n",
    "        self.P = self.P - dot(K, self.H).dot(self.P)\n",
    "        self.x_state = x.astype(int) # convert to integer coordinates \n",
    "                                     #(pixel values)\n",
    "        \n",
    "    def predict_only(self):  \n",
    "        '''\n",
    "        Implment only the predict stage. This is used for unmatched detections and \n",
    "        unmatched tracks\n",
    "        '''\n",
    "        x = self.x_state\n",
    "        # Predict\n",
    "        x = dot(self.F, x)\n",
    "        self.P = dot(self.F, self.P).dot(self.F.T) + self.Q\n",
    "        self.x_state = x.astype(int)\n",
    "\n",
    "\n",
    "def box_iou2(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def assign_detections_to_trackers(trackers, detections, iou_thrd = 0.3):\n",
    "    '''\n",
    "    From current list of trackers and new detections, output matched detections,\n",
    "    unmatchted trackers, unmatched detections.\n",
    "    '''    \n",
    "    \n",
    "    IOU_mat= np.zeros((len(trackers),len(detections)),dtype=np.float32)\n",
    "    for t,trk in enumerate(trackers):\n",
    "        #trk = convert_to_cv2bbox(trk) \n",
    "        for d,det in enumerate(detections):\n",
    "            IOU_mat[t,d] = box_iou2(trk,det) \n",
    "    \n",
    "    # Produces matches       \n",
    "    # Solve the maximizing the sum of IOU assignment problem using the\n",
    "    # Hungarian algorithm (also known as Munkres algorithm)\n",
    "    \n",
    "    matched_idx = linear_assignment(-IOU_mat)\n",
    "\n",
    "    unmatched_trackers, unmatched_detections = [], []\n",
    "    for t,trk in enumerate(trackers):\n",
    "        if(t not in matched_idx[:,0]):\n",
    "            unmatched_trackers.append(t)\n",
    "\n",
    "    for d, det in enumerate(detections):\n",
    "        if(d not in matched_idx[:,1]):\n",
    "            unmatched_detections.append(d)\n",
    "\n",
    "    matches = []\n",
    "   \n",
    "    # For creating trackers we consider any detection with an \n",
    "    # overlap less than iou_thrd to signifiy the existence of \n",
    "    # an untracked object\n",
    "    \n",
    "    for m in matched_idx:\n",
    "        if(IOU_mat[m[0],m[1]]<iou_thrd):\n",
    "            unmatched_trackers.append(m[0])\n",
    "            unmatched_detections.append(m[1])\n",
    "        else:\n",
    "            matches.append(m.reshape(1,2))\n",
    "    \n",
    "    if(len(matches)==0):\n",
    "        matches = np.empty((0,2),dtype=int)\n",
    "    else:\n",
    "        matches = np.concatenate(matches,axis=0)\n",
    "    \n",
    "    return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n",
    "\n",
    "\n",
    "class Box:\n",
    "    def __init__(self):\n",
    "        self.x, self.y = float(), float()\n",
    "        self.w, self.h = float(), float()\n",
    "        self.c = float()\n",
    "        self.prob = float()\n",
    "\n",
    "def overlap(x1,w1,x2,w2):\n",
    "    l1 = x1 - w1 / 2.;\n",
    "    l2 = x2 - w2 / 2.;\n",
    "    left = max(l1, l2)\n",
    "    r1 = x1 + w1 / 2.;\n",
    "    r2 = x2 + w2 / 2.;\n",
    "    right = min(r1, r2)\n",
    "    return right - left;\n",
    "\n",
    "def box_intersection(a, b):\n",
    "    w = overlap(a.x, a.w, b.x, b.w);\n",
    "    h = overlap(a.y, a.h, b.y, b.h);\n",
    "    if w < 0 or h < 0: return 0;\n",
    "    area = w * h;\n",
    "    return area;\n",
    "\n",
    "def box_union(a, b):\n",
    "    i = box_intersection(a, b);\n",
    "    u = a.w * a.h + b.w * b.h - i;\n",
    "    return u;\n",
    "\n",
    "def box_iou(a, b):\n",
    "    return box_intersection(a, b) / box_union(a, b);\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Kalman filter based tracker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arslan/.conda/envs/python37/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "global frame_count\n",
    "global tracker_list\n",
    "global max_age\n",
    "global min_hits\n",
    "global track_id_list\n",
    "global debug\n",
    "\n",
    "# Global variables to be used by funcitons of VideoFileClop\n",
    "frame_count = 0 # frame counter\n",
    "max_age = maxDisappeared\n",
    "\n",
    "min_hits =1  # no. of consecutive matches needed to establish a track\n",
    "\n",
    "tracker_list =[] # list for trackers\n",
    "# list for track ID (0-49)\n",
    "# track_id_list= deque(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R'])\n",
    "track_id_list= deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
    "\n",
    "debug = True\n",
    "\n",
    "xx_kalman = np.zeros(shape=(len(images), max_objects))\n",
    "yy_kalman = np.zeros(shape=(len(images), max_objects))\n",
    "length_path = len(images)\n",
    "labelled = []\n",
    "\n",
    "if len(pred_car) == len(pred_bus):\n",
    "    print(\"Initializing Kalman filter based tracker\")\n",
    "\n",
    "    for i, car in enumerate(pred_car):\n",
    "        z_box = car + pred_bus[i]\n",
    "        frame_count+=1\n",
    "        img = images[i].copy()\n",
    "        x_box =[]\n",
    "        \n",
    "\n",
    "        if len(tracker_list) > 0:\n",
    "            for trk in tracker_list:\n",
    "                x_box.append(trk.box)\n",
    "\n",
    "        matched, unmatched_dets, unmatched_trks = assign_detections_to_trackers(x_box, z_box, iou_thrd = 0.3)  \n",
    "\n",
    "        # Deal with matched detections     \n",
    "        if matched.size >0:\n",
    "            for trk_idx, det_idx in matched:\n",
    "                z = z_box[det_idx]\n",
    "                z = np.expand_dims(z, axis=0).T\n",
    "                tmp_trk= tracker_list[trk_idx]\n",
    "                tmp_trk.kalman_filter(z)\n",
    "                xx = tmp_trk.x_state.T[0].tolist()\n",
    "                xx =[xx[0], xx[2], xx[4], xx[6]]\n",
    "                x_box[trk_idx] = xx\n",
    "                tmp_trk.box =xx\n",
    "                tmp_trk.hits += 1\n",
    "                tmp_trk.no_losses = 0\n",
    "\n",
    "        # Deal with unmatched detections      \n",
    "        if len(unmatched_dets)>0:\n",
    "            for idx in unmatched_dets:\n",
    "                z = z_box[idx]\n",
    "                z = np.expand_dims(z, axis=0).T\n",
    "                tmp_trk = Tracker() # Create a new tracker\n",
    "                x = np.array([[z[0], 0, z[1], 0, z[2], 0, z[3], 0]]).T\n",
    "                tmp_trk.x_state = x\n",
    "                tmp_trk.predict_only()\n",
    "                xx = tmp_trk.x_state\n",
    "                xx = xx.T[0].tolist()\n",
    "                xx =[xx[0], xx[2], xx[4], xx[6]]\n",
    "                tmp_trk.box = xx\n",
    "                tmp_trk.id = track_id_list.popleft() # assign an ID for the tracker\n",
    "                tracker_list.append(tmp_trk)\n",
    "                x_box.append(xx)\n",
    "\n",
    "        # Deal with unmatched tracks       \n",
    "        if len(unmatched_trks)>0:\n",
    "            for trk_idx in unmatched_trks:\n",
    "                tmp_trk = tracker_list[trk_idx]\n",
    "                tmp_trk.no_losses += 1\n",
    "                tmp_trk.predict_only()\n",
    "                xx = tmp_trk.x_state\n",
    "                xx = xx.T[0].tolist()\n",
    "                xx =[xx[0], xx[2], xx[4], xx[6]]\n",
    "                tmp_trk.box =xx\n",
    "                x_box[trk_idx] = xx\n",
    "\n",
    "\n",
    "        # The list of tracks to be annotated  \n",
    "        good_tracker_list =[]\n",
    "        for trk in tracker_list:\n",
    "            if ((trk.hits >= min_hits) and (trk.no_losses <=max_age)):\n",
    "                good_tracker_list.append(trk)\n",
    "                x_cv2 = trk.box\n",
    "                    \n",
    "                center_x = int((x_cv2[0] + x_cv2[2]) / 2.0)\n",
    "                center_y = int((x_cv2[1] + x_cv2[3]) / 2.0)\n",
    "                xx_kalman[i,trk.id] = center_x\n",
    "                yy_kalman[i,trk.id] = center_y\n",
    "                \n",
    "        deleted_tracks = filter(lambda x: x.no_losses >max_age, tracker_list)  \n",
    "\n",
    "        for trk in deleted_tracks:\n",
    "            track_id_list.append(trk.id)\n",
    "\n",
    "        tracker_list = [x for x in tracker_list if x.no_losses<=max_age]\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled = []\n",
    "pts_list = []\n",
    "colors = []\n",
    "for i in range(max_objects):\n",
    "    pts_list.append(deque(maxlen=length_path))\n",
    "    colors.append((np.random.randint(low=0, high=255), np.random.randint(low=0, high=255), np.random.randint(low=0, high=255)))\n",
    "\n",
    "for k in range(xx_kalman.shape[0]):\n",
    "    img = images[k].copy()\n",
    "    for j in range(xx_kalman.shape[1]):\n",
    "        pts_list[j].appendleft((int(xx_kalman[k,j]), int(yy_kalman[k,j])))       \n",
    "        for i in range(1, len(pts_list[j])):\n",
    "            if pts_list[j][i - 1] is None or pts_list[j][i] is None:\n",
    "                continue\n",
    "            thickness = 4\n",
    "            d = int(calculateDistance(pts_list[j][i - 1][0], pts_list[j][i-1][1], pts_list[j][i][0], pts_list[j][i][1]))\n",
    "            if d<100:\n",
    "                cv2.line(img, pts_list[j][i - 1], pts_list[j][i], colors[j], thickness)\n",
    "                \n",
    "#     cv2.imshow(\"Image\", img)\n",
    "#     cv2.waitKey(0)\n",
    "    labelled.append(img)\n",
    "    \n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video_path = os.path.join(os.getcwd(), \"kalmanFilter_tracker.mp4\")\n",
    "convert_frames_to_video(labelled, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask_rcnn",
   "language": "python",
   "name": "mask_rcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
